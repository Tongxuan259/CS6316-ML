{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training set and development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2430, 3) (2430,)\n",
      "(270, 3) (270,)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_X_PATH = \"./trnX-3d.csv\"\n",
    "TRAIN_Y_PATH = \"./trnY-3d.csv\"\n",
    "\n",
    "VALID_X_PATH = \"./devX-3d.csv\"\n",
    "VALID_Y_PATH = \"./devY-3d.csv\"\n",
    "\n",
    "def read_csv_data(file_path):\n",
    "    # Read the CSV file using pandas\n",
    "    data = pd.read_csv(file_path, sep=\"\\t\", header=None)\n",
    "\n",
    "    # Return the DataFrame\n",
    "    return np.array(data.values)\n",
    "\n",
    "def load_train_data(train_x_path, train_y_path):\n",
    "\n",
    "    train_x = read_csv_data(train_x_path)\n",
    "    train_y = read_csv_data(train_y_path)\n",
    "    train_y = train_y.reshape(train_y.shape[0])\n",
    "\n",
    "    return train_x, train_y\n",
    "\n",
    "def load_valid_data(valid_x_path, valid_y_path):\n",
    "\n",
    "    train_x = read_csv_data(valid_x_path)\n",
    "    train_y = read_csv_data(valid_y_path)\n",
    "    train_y = train_y.reshape(train_y.shape[0])\n",
    "\n",
    "    return train_x, train_y\n",
    "\n",
    "train_x, train_y = load_train_data(train_x_path=TRAIN_X_PATH, train_y_path=TRAIN_Y_PATH)\n",
    "\n",
    "valid_x, valid_y = load_valid_data(valid_x_path=VALID_X_PATH, valid_y_path=VALID_Y_PATH)\n",
    "\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier Initialization and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on development set : 83.3%\n",
      "Accuracy on training set    : 82.5%\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(random_state=123, max_iter=1000)   # set fixed random state to ensure reproducibility\n",
    "\n",
    "mlp.fit(train_x, train_y)\n",
    "\n",
    "predict_valid_y = mlp.predict(valid_x)\n",
    "predict_train_y = mlp.predict(train_x)\n",
    "\n",
    "print(f\"Accuracy on development set : {round(accuracy_score(valid_y, predict_valid_y), 3) * 100}%\")\n",
    "print(f\"Accuracy on training set    : {round(accuracy_score(train_y, predict_train_y), 3) * 100}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem (b)\n",
    "### Hyper-parameter tuning\n",
    "Make take about 60 minutes ~ (depends on your cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Best Parameter ===============\n",
      "hidden_layer_sizes\t: (1000, 500)\n",
      "activation\t\t: relu\n",
      "solver\t\t\t: adam\n",
      "learning_rate_init\t: 0.0005\n",
      "batch_size\t\t: 128\n",
      "Validation Accuracy\t: 86.667%\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = 8\n",
    "MULTI_PROC  = True\n",
    "\n",
    "def train_and_evaluate(combination, train_x, train_y, valid_x, valid_y):\n",
    "    hidden_layer_sizes, activation, solver, learning_rate_init, batch_size = combination\n",
    "    \n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, learning_rate_init=learning_rate_init, batch_size=batch_size, random_state=123, max_iter=1000)\n",
    "    mlp.fit(train_x, train_y)\n",
    "    predictions = mlp.predict(valid_x)\n",
    "\n",
    "    score = accuracy_score(valid_y, predictions)\n",
    "    return score, combination, mlp\n",
    "\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(500), (1000, 500), (1000, 500, 200)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate_init': [0.01, 0.001, 0.0005],\n",
    "    'batch_size': [64, 128, 256]\n",
    "}\n",
    "# parameter_space = {\n",
    "#     'hidden_layer_sizes': [(1000, 500)],\n",
    "#     'activation': ['relu'],\n",
    "#     'solver': ['adam'],\n",
    "#     'learning_rate_init': [0.0005],\n",
    "#     'batch_size': [128]\n",
    "# }\n",
    "\n",
    "param_combinations = list(itertools.product(\n",
    "    parameter_space['hidden_layer_sizes'],\n",
    "    parameter_space['activation'],\n",
    "    parameter_space['solver'],\n",
    "    parameter_space['learning_rate_init'],\n",
    "    parameter_space['batch_size']\n",
    "))\n",
    "\n",
    "best_score = 0\n",
    "best_params = {}\n",
    "best_model = None\n",
    "\n",
    "if MULTI_PROC:\n",
    "    import concurrent\n",
    "    from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=NUM_WORKERS) as executor:\n",
    "        futures = [executor.submit(train_and_evaluate, combination, train_x, train_y, valid_x, valid_y) for combination in param_combinations]\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            score, params, model = future.result()\n",
    "            hidden_layer_sizes, activation, solver, learning_rate_init, batch_size = params\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_params = {'hidden_layer_sizes': hidden_layer_sizes, 'activation': activation, 'solver': solver, 'learning_rate_init': learning_rate_init, 'batch_size': batch_size}\n",
    "else:\n",
    "    for combination in param_combinations:\n",
    "        hidden_layer_sizes, activation, solver, learning_rate_init, batch_size = combination\n",
    "\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, learning_rate_init=learning_rate_init, batch_size=batch_size)\n",
    "        mlp.fit(train_x, train_y)\n",
    "\n",
    "        predictions = mlp.predict(valid_x)\n",
    "        score = accuracy_score(valid_y, predictions)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = mlp\n",
    "            best_params = {'hidden_layer_sizes': hidden_layer_sizes, 'activation': activation, 'solver': solver, 'learning_rate_init': learning_rate_init, 'batch_size': batch_size}\n",
    "\n",
    "print(\"=\"*15, \"Best Parameter\", \"=\"*15)\n",
    "print('hidden_layer_sizes\\t:', best_params['hidden_layer_sizes'])\n",
    "print('activation\\t\\t:', best_params['activation'])\n",
    "print('solver\\t\\t\\t:', best_params['solver'])\n",
    "print('learning_rate_init\\t:', best_params['learning_rate_init'])\n",
    "print('batch_size\\t\\t:', best_params['batch_size'])\n",
    "print('Validation Accuracy\\t:', str(round(best_score*100, 3)) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predition for test data: \n",
      " [0 1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0\n",
      " 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1\n",
      " 0 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 0 1 1 0\n",
      " 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0\n",
      " 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0\n",
      " 0 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1\n",
      " 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 1\n",
      " 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "SAVE_TO_CSV =True\n",
    "\n",
    "test_x = read_csv_data(\"./tstX-3d.csv\")\n",
    "\n",
    "# mlp = MLPClassifier(hidden_layer_sizes=best_params[\"hidden_layer_sizes\"],\n",
    "#                     activation=best_params[\"activation\"],\n",
    "#                     solver=best_params[\"solver\"],\n",
    "#                     learning_rate_init=best_params[\"learning_rate_init\"],\n",
    "#                     batch_size=best_params[\"batch_size\"],\n",
    "#                     max_iter=1000,\n",
    "#                     random_state=123)\n",
    "best_mlp = best_model\n",
    "\n",
    "# best_mlp.fit(train_x, train_y)\n",
    "\n",
    "predict_test_y = best_mlp.predict(test_x)\n",
    "print(\"Predition for test data: \\n\", predict_test_y)\n",
    "\n",
    "if SAVE_TO_CSV:\n",
    "    pred_test_y_df = pd.DataFrame({\"prediction\": predict_test_y})\n",
    "    pred_test_y_df.to_csv('tstY-3d.csv', header=None, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttx_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
